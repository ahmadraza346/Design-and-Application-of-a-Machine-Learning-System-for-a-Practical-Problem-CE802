{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Read CSV file into DataFrame train_data\n",
    "train_data = pd.read_csv('CE802_P2_Data.csv')\n",
    "#check for null values\n",
    "#train_data.isnull().sum()\n",
    "FX1=train_data.drop(columns=['Class','F21'])\n",
    "FY1=train_data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Support Vector Classification without performing any feature-engineering,  hyper-parameter tuning, cross-validation or pipelining, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[68 31]\n",
      " [28 73]]\n",
      "Accuracy Score : 0.705\n",
      "F1 Score : 0.7121951219512195\n",
      "Precision Score : 0.7019230769230769\n",
      "Recall Score : 0.7227722772277227\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns=['Class','F21'])\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "X_test=scalar.transform(X_test)\n",
    "clf=SVC()\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Support Vector Classification Algorithm while dropping the Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 100, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Average accuracy 0.7112499999999999\n",
      "Confusion Matrix : \n",
      "[[66 33]\n",
      " [19 82]]\n",
      "Accuracy Score : 0.74\n",
      "F1 Score : 0.7592592592592593\n",
      "Precision Score : 0.7130434782608696\n",
      "Recall Score : 0.8118811881188119\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "dropper = ColumnTransformer([('dropper', 'drop', 20)], remainder='passthrough')\n",
    "svc=SVC()\n",
    "pipe = Pipeline([('dropper', dropper) , ('svc', svc)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100, 1000], 'svc__gamma': [ 0.0001, 0.001, 0.01, 0.1, 1], 'svc__kernel': ['rbf' , 'linear']}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "X_test=scalar.transform(X_test)\n",
    "pipes = Pipeline([('dropper', dropper)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Support Vector Classification Algorithm while taking mean by SimpleImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1000, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Average accuracy 0.74125\n",
      "Confusion Matrix : \n",
      "[[73 26]\n",
      " [24 77]]\n",
      "Accuracy Score : 0.75\n",
      "F1 Score : 0.7549019607843138\n",
      "Precision Score : 0.7475728155339806\n",
      "Recall Score : 0.7623762376237624\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "mean= SimpleImputer(strategy='mean', fill_value='Missing')\n",
    "scalar=StandardScaler()\n",
    "svc=SVC()\n",
    "pipe = Pipeline([('mean', mean), ('scalar',scalar) , ('svc', svc)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100, 1000], 'svc__gamma': [ 0.0001, 0.001, 0.01, 0.1, 1], 'svc__kernel': ['rbf' , 'linear']}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Support Vector Classification Algorithm while taking mean by IterativeImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1000, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "Average accuracy 0.7225\n",
      "Confusion Matrix : \n",
      "[[73 26]\n",
      " [23 78]]\n",
      "Accuracy Score : 0.755\n",
      "F1 Score : 0.7609756097560977\n",
      "Precision Score : 0.75\n",
      "Recall Score : 0.7722772277227723\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "mean= IterativeImputer(random_state=0)\n",
    "scalar=StandardScaler()\n",
    "svc=SVC()\n",
    "#defining my pipeline\n",
    "pipe = Pipeline([('mean', mean), ('scalar',scalar) , ('svc', svc)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100, 1000], 'svc__gamma': [ 0.0001, 0.001, 0.01, 0.1, 1], 'svc__kernel': ['rbf' , 'linear']}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing K Nearest Neighbour without performing any feature-engineering,  hyper-parameter tuning, cross-validation or pipelining, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[62 37]\n",
      " [43 58]]\n",
      "Accuracy Score : 0.6\n",
      "F1 Score : 0.5918367346938775\n",
      "Precision Score : 0.6105263157894737\n",
      "Recall Score : 0.5742574257425742\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns=['Class','F21'])\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "X_test=scalar.transform(X_test)\n",
    "clf=KNeighborsClassifier()\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing K Nearest Neighbour Algorithm while dropping the Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__leaf_size': 1, 'knn__n_neighbors': 36, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Average accuracy 0.6587500000000001\n",
      "Confusion Matrix : \n",
      "[[75 24]\n",
      " [45 56]]\n",
      "Accuracy Score : 0.655\n",
      "F1 Score : 0.6187845303867403\n",
      "Precision Score : 0.7\n",
      "Recall Score : 0.5544554455445545\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "dropper = ColumnTransformer([('dropper', 'drop', 20)], remainder='passthrough')\n",
    "knn = KNeighborsClassifier()\n",
    "pipe = Pipeline([('dropper', dropper) , ('knn', knn)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'knn__leaf_size':list(range(1,45)), 'knn__n_neighbors':list(range(1,100)), 'knn__p': [1,2], 'knn__weights': ['uniform' , 'distance']}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "X_test=scalar.transform(X_test)\n",
    "pipes = Pipeline([('dropper', dropper)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing K Nearest Neighbour Algorithm while taking mean by SimpleImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__leaf_size': 1, 'knn__n_neighbors': 32, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Average accuracy 0.6950000000000001\n",
      "Confusion Matrix : \n",
      "[[78 21]\n",
      " [40 61]]\n",
      "Accuracy Score : 0.695\n",
      "F1 Score : 0.6666666666666667\n",
      "Precision Score : 0.7439024390243902\n",
      "Recall Score : 0.6039603960396039\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "mean= SimpleImputer(strategy='mean', fill_value='Missing')\n",
    "scalar=StandardScaler()\n",
    "knn = KNeighborsClassifier()\n",
    "pipe = Pipeline([('mean', mean), ('scalar',scalar) , ('knn', knn)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'knn__leaf_size':list(range(1,45)), 'knn__n_neighbors':list(range(1,100)), 'knn__p': [1,2] , 'knn__weights': ['uniform' , 'distance']}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing K Nearest Neighbour Algorithm while taking mean by IterativeImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__leaf_size': 1, 'knn__n_neighbors': 33, 'knn__p': 1}\n",
      "Average accuracy 0.6950000000000001\n",
      "Confusion Matrix : \n",
      "[[82 17]\n",
      " [42 59]]\n",
      "Accuracy Score : 0.705\n",
      "F1 Score : 0.6666666666666666\n",
      "Precision Score : 0.7763157894736842\n",
      "Recall Score : 0.5841584158415841\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "mean= IterativeImputer(random_state=0)\n",
    "scalar=StandardScaler()\n",
    "knn = KNeighborsClassifier()\n",
    "pipe = Pipeline([('mean', mean), ('scalar',scalar) , ('knn', knn)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'knn__leaf_size':list(range(1,45)), 'knn__n_neighbors':list(range(1,100)), 'knn__p': [1,2]}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Decision Tree Classifier without performing any feature-engineering,  hyper-parameter tuning, cross-validation or pipelining, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[74 25]\n",
      " [21 80]]\n",
      "Accuracy Score : 0.77\n",
      "F1 Score : 0.7766990291262137\n",
      "Precision Score : 0.7619047619047619\n",
      "Recall Score : 0.7920792079207921\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns=['Class','F21'])\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "X_test=scalar.transform(X_test)\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Decision Tree Classifier Algorithm while dropping the Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dtc__criterion': 'entropy', 'dtc__max_depth': 3, 'dtc__min_samples_leaf': 0.1, 'dtc__min_samples_split': 0.1}\n",
      "Average accuracy 0.7799999999999999\n",
      "Confusion Matrix : \n",
      "[[66 33]\n",
      " [15 86]]\n",
      "Accuracy Score : 0.76\n",
      "F1 Score : 0.7818181818181817\n",
      "Precision Score : 0.7226890756302521\n",
      "Recall Score : 0.8514851485148515\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "scalar=StandardScaler()\n",
    "dropper = ColumnTransformer([('dropper', 'drop', 20)], remainder='passthrough')\n",
    "dtc = DecisionTreeClassifier()\n",
    "pipe = Pipeline([('dropper', dropper) ,('scalar',scalar), ('dtc', dtc)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'dtc__criterion':['gini', 'entropy'],'dtc__max_depth':list(range(1,25)),'dtc__min_samples_split' :np.linspace(0.1, 1.0, 10, endpoint=True), 'dtc__min_samples_leaf' : np.linspace(0.1, 0.5, 10, endpoint=True)} \n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('dropper', dropper)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Decision Tree Classifier Algorithm while taking mean by SimpleImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dtc__criterion': 'entropy', 'dtc__max_depth': 3, 'dtc__min_samples_leaf': 0.1, 'dtc__min_samples_split': 0.1}\n",
      "Average accuracy 0.7762500000000001\n",
      "Confusion Matrix : \n",
      "[[66 33]\n",
      " [15 86]]\n",
      "Accuracy Score : 0.76\n",
      "F1 Score : 0.7818181818181817\n",
      "Precision Score : 0.7226890756302521\n",
      "Recall Score : 0.8514851485148515\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "mean= SimpleImputer(strategy='mean', fill_value='Missing')\n",
    "scalar=StandardScaler()\n",
    "dtc = DecisionTreeClassifier()\n",
    "pipe = Pipeline([('mean', mean), ('scalar',scalar) , ('dtc', dtc)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'dtc__criterion':['gini', 'entropy'],'dtc__max_depth':list(range(1,25)),'dtc__min_samples_split' :np.linspace(0.1, 1.0, 10, endpoint=True), 'dtc__min_samples_leaf' : np.linspace(0.1, 0.5, 10, endpoint=True)} \n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Decision Tree Classifier Algorithm while taking mean by IterativeImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dtc__criterion': 'entropy', 'dtc__max_depth': 3, 'dtc__min_samples_leaf': 0.1, 'dtc__min_samples_split': 0.1}\n",
      "Average accuracy 0.76125\n",
      "Confusion Matrix : \n",
      "[[69 30]\n",
      " [15 86]]\n",
      "Accuracy Score : 0.775\n",
      "F1 Score : 0.792626728110599\n",
      "Precision Score : 0.7413793103448276\n",
      "Recall Score : 0.8514851485148515\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "mean= IterativeImputer(random_state=0)\n",
    "scalar=StandardScaler()\n",
    "dtc = DecisionTreeClassifier()\n",
    "pipe = Pipeline([('mean', mean), ('scalar',scalar) , ('dtc', dtc)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'dtc__criterion':['gini', 'entropy'],'dtc__max_depth':list(range(1,25)),'dtc__min_samples_split' :np.linspace(0.1, 1.0, 10, endpoint=True), 'dtc__min_samples_leaf' : np.linspace(0.1, 0.5, 10, endpoint=True)} \n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Random Forest Classifier without performing any feature-engineering,  hyper-parameter tuning, cross-validation or pipelining, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[80 19]\n",
      " [16 85]]\n",
      "Accuracy Score : 0.825\n",
      "F1 Score : 0.8292682926829268\n",
      "Precision Score : 0.8173076923076923\n",
      "Recall Score : 0.8415841584158416\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns=['Class','F21'])\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "X_test=scalar.transform(X_test)\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(X,Y)\n",
    "y_pred = clf.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Random Forest Classifier Algorithm while dropping Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__criterion': 'entropy', 'clf__min_samples_split': 0.1, 'clf__n_estimators': 15}\n",
      "Average accuracy 0.7737499999999999\n",
      "Confusion Matrix : \n",
      "[[77 22]\n",
      " [20 81]]\n",
      "Accuracy Score : 0.79\n",
      "F1 Score : 0.7941176470588236\n",
      "Precision Score : 0.7864077669902912\n",
      "Recall Score : 0.801980198019802\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)                                        \n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "scalar=StandardScaler()\n",
    "dropper = ColumnTransformer([('dropper', 'drop', 20)], remainder='passthrough')\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "pipe = Pipeline([('dropper', dropper) ,('scalar',scalar), ('clf', clf)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'clf__criterion':['gini', 'entropy'],'clf__n_estimators':list(range(5,25)),'clf__min_samples_split' :np.linspace(0.1, 1.0, 10, endpoint=True)} \n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('dropper', dropper)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Random Forest Classifier Algorithm while taking mean by SimpleImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__criterion': 'entropy', 'clf__min_samples_split': 0.1, 'clf__n_estimators': 24}\n",
      "Average accuracy 0.8\n",
      "Confusion Matrix : \n",
      "[[79 20]\n",
      " [13 88]]\n",
      "Accuracy Score : 0.835\n",
      "F1 Score : 0.8421052631578947\n",
      "Precision Score : 0.8148148148148148\n",
      "Recall Score : 0.8712871287128713\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "scalar=StandardScaler()\n",
    "X=scalar.fit_transform(X)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "mean= SimpleImputer(strategy='mean', fill_value='Missing')\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "pipe = Pipeline([('mean', mean) , ('clf', clf)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'clf__criterion':['gini', 'entropy'],'clf__n_estimators':list(range(5,25)),'clf__min_samples_split' :np.linspace(0.1, 1.0, 10, endpoint=True)} \n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "X_test=scalar.transform(X_test)\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Random Forest Classifier Algorithm while taking mean by IterativeImputer for Feature21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__criterion': 'entropy', 'clf__min_samples_split': 0.1, 'clf__n_estimators': 13}\n",
      "Average accuracy 0.8012499999999999\n",
      "Confusion Matrix : \n",
      "[[75 24]\n",
      " [11 90]]\n",
      "Accuracy Score : 0.825\n",
      "F1 Score : 0.8372093023255814\n",
      "Precision Score : 0.7894736842105263\n",
      "Recall Score : 0.8910891089108911\n"
     ]
    }
   ],
   "source": [
    "#specifying targets and labels\n",
    "X1=train_data.drop(columns='Class')\n",
    "Y1=train_data['Class']\n",
    "#splitting the data\n",
    "X, X_test, Y, Y_test = train_test_split(X1, Y1, train_size=0.80, random_state=1, stratify=Y1)\n",
    "#defining the number of folds in cross-validation\n",
    "cv = KFold(n_splits=5,shuffle=True)\n",
    "#defining my pipeline\n",
    "scalar=StandardScaler()\n",
    "mean= IterativeImputer(random_state=0)\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "pipe = Pipeline([('mean', mean) ,('scalar',scalar), ('clf', clf)])\n",
    "#performing grid-search to tune-hyper-parameters\n",
    "param_grid = {'clf__criterion':['gini', 'entropy'],'clf__n_estimators':list(range(5,25)),'clf__min_samples_split' :np.linspace(0.1, 1.0, 10, endpoint=True)}  \n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#fitting the pipeline\n",
    "search.fit(X,Y)\n",
    "print(search.best_params_)\n",
    "#computing the average accuracy score while performing cross-validation on different folds\n",
    "scores = cross_validate(search, X, Y, scoring=['accuracy'], cv=cv, return_estimator=True)\n",
    "print('Average accuracy', np.mean(scores['test_accuracy']))\n",
    "#predicting the values on the test data\n",
    "pipes = Pipeline([('mean', mean)])\n",
    "pipes.fit_transform(X_test)\n",
    "y_pred = search.predict(X_test)\n",
    "#Analyzing the results\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(Y_test,y_pred)))\n",
    "print('Accuracy Score : ' + str(accuracy_score(Y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(Y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(Y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(Y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Feature Engineering by using the confusionmatrix method to find which features are co-related.\n",
    "On performing this method, it can been seen that no feature is co-related to the other feature even at 50 percent. \n",
    "So, no features can be dropped.\n",
    "Note: Code is used from Project-pro\n",
    "https://www.projectpro.io/recipes/drop-out-highly-correlated-features-in-python#:~:text=%20How%20to%20drop%20out%20highly%20correlated%20features,trigular%20matrix.%20So%20now%20we%20are...%20More%20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "correlation = FX1.corr().abs()\n",
    "upper_triangle = correlation.where(np.triu(np.ones(correlation.shape),k=1).astype(bool))\n",
    "#dropping columns having correlation greater than 90 percent\n",
    "dropping = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.70)]\n",
    "print(dropping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scalar=StandardScaler()\n",
    "FX1=scalar.fit_transform(FX1)\n",
    "model=RandomForestClassifier()\n",
    "model=model.fit(FX1,FY1)\n",
    "importance = model.feature_importances_\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on best accuracy algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the the best algorithm(Random Forest Classifier) while dropping the F21 using best hyperparameters got by gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', min_samples_split=0.1,\n",
       "                       n_estimators=24)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X11=train_data.drop(columns=['Class'])\n",
    "Y11=train_data['Class']\n",
    "mean= SimpleImputer(strategy='mean', fill_value='Missing')\n",
    "X11=mean.fit_transform(X11)\n",
    "scalar=StandardScaler()\n",
    "X11=scalar.fit_transform(X11)\n",
    "rfc=RandomForestClassifier(criterion='entropy',min_samples_split=0.1,n_estimators=24)\n",
    "rfc.fit(X11,Y11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Values on Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_df = pd.read_csv('CE802_P2_Test.csv')\n",
    "#making copy of test data to perform different functions\n",
    "test_data = pd.read_csv('CE802_P2_Test.csv')\n",
    "#defining the targets and features\n",
    "X1=test_data.drop(columns=['Class'])\n",
    "Y1=test_data['Class']\n",
    "mean= SimpleImputer(strategy='mean', fill_value='Missing')\n",
    "X1=mean.fit_transform(X1)\n",
    "#performing standard scaling\n",
    "scalar=StandardScaler()\n",
    "X1=scalar.fit_transform(X1)\n",
    "#predicting the class values on trained algorithm\n",
    "predicted = rfc.predict(X1)\n",
    "# Replacing the last (empty) column with my predictions\n",
    "test_df.iloc[:,-1] = predicted\n",
    "# Save my predictions to the destination file\n",
    "test_df.to_csv('CE802_P2_Test_Predictions.csv', index=False, float_format='%.8g')\n",
    "# writing back to the csv file\n",
    "assert pd.read_csv('CE802_P2_Test.csv').iloc[:,:-1].equals(pd.read_csv('CE802_P2_Test_Predictions.csv').iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
